{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d25dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Linear_Regression:\n",
    "    def __init__(self,learning_rate=0.01,epochs=100):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self,X,Y):\n",
    "        X = np.asarray(X,dtype=np.float64) \n",
    "        Y = np.asarray(Y,dtype=np.float64)\n",
    "\n",
    "        m,n = X.shape\n",
    "        self.weights = np.zeros((n,1))\n",
    "        self.bias = 0\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            y_pred = X @ self.weights + self.bias     #(m,1)\n",
    "\n",
    "            dw = (1/m)*(X.T @ (y_pred - Y))\n",
    "            db = (1/m)*np.sum(y_pred - Y)\n",
    "\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "\n",
    "            self.calculate_loss(Y,y_pred)\n",
    "\n",
    "        return self    \n",
    "\n",
    "    def calculate_loss(self,Y,y_pred):\n",
    "        return np.mean((Y - y_pred)**2)\n",
    "\n",
    "    def predict(self,X):\n",
    "        X = np.asarray(X,dtype=np.float64)\n",
    "        y_pred = X @ self.weights + self.bias\n",
    "        return y_pred\n",
    "    \n",
    "np.random.seed(42)\n",
    "X = np.random.randn(200,4)\n",
    "Y = np.random.randn(200,1)\n",
    "\n",
    "model = Linear_Regression()\n",
    "model.fit(X,Y)\n",
    "\n",
    "print(model.predict(X[:10]))\n",
    "print(\"-------\")\n",
    "print(Y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be172048",
   "metadata": {},
   "source": [
    "Cell 0 — Title & Plan (optional but nice)\n",
    "\n",
    "Briefly list: objective, loss (MSE), optimizer (batch GD), regularization (L2 optional), metrics (MSE/RMSE/R²), early stopping.\n",
    "\n",
    "Say out loud in interview: “I’ll implement linear regression with MSE + L2, trained by batch gradient descent, vectorized with NumPy.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de3d0d4",
   "metadata": {},
   "source": [
    "Cell 1 — Imports, Reproducibility, Dtypes\n",
    "\n",
    "Import NumPy only (and matplotlib if you want a loss plot later).\n",
    "\n",
    "Set a random seed.\n",
    "\n",
    "Decide float64 everywhere (stability).\n",
    "\n",
    "Note: You will avoid Python loops in the core math—use @ (matmul).\n",
    "\n",
    "Checks\n",
    "\n",
    "Print NumPy version (optional).\n",
    "\n",
    "Explain: “I’ll stick to vectorized ops to keep it O(nd) per epoch.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af905323",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe78a15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e479c9",
   "metadata": {},
   "source": [
    "A] Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8329ddb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_train.csv')\n",
    "df_test = pd.read_csv('data_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20cca3a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>NMHC(GT)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>NOx(GT)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>NO2(GT)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>797.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>593.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>1212.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>984.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>49.7</td>\n",
       "      <td>0.6429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1282.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1013.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>545.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>1384.0</td>\n",
       "      <td>1287.0</td>\n",
       "      <td>17.4</td>\n",
       "      <td>50.6</td>\n",
       "      <td>0.9989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>891.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>882.0</td>\n",
       "      <td>342.0</td>\n",
       "      <td>885.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>950.0</td>\n",
       "      <td>894.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>33.9</td>\n",
       "      <td>0.3594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1285.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>18.1</td>\n",
       "      <td>1243.0</td>\n",
       "      <td>481.0</td>\n",
       "      <td>599.0</td>\n",
       "      <td>173.0</td>\n",
       "      <td>1815.0</td>\n",
       "      <td>1582.0</td>\n",
       "      <td>26.4</td>\n",
       "      <td>41.9</td>\n",
       "      <td>1.4237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>892.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>869.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>953.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>1363.0</td>\n",
       "      <td>632.0</td>\n",
       "      <td>37.4</td>\n",
       "      <td>14.7</td>\n",
       "      <td>0.9295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PT08.S1(CO)  NMHC(GT)  C6H6(GT)  PT08.S2(NMHC)  NOx(GT)  PT08.S3(NOx)  \\\n",
       "0        797.0    -200.0       2.1          593.0    146.0        1212.0   \n",
       "1       1282.0    -200.0      11.0         1013.0    354.0         545.0   \n",
       "2        891.0    -200.0       7.6          882.0    342.0         885.0   \n",
       "3       1285.0    -200.0      18.1         1243.0    481.0         599.0   \n",
       "4        892.0    -200.0       7.3          869.0     71.0         953.0   \n",
       "\n",
       "   NO2(GT)  PT08.S4(NO2)  PT08.S5(O3)     T    RH      AH  \n",
       "0     72.0         984.0        494.0  10.8  49.7  0.6429  \n",
       "1    141.0        1384.0       1287.0  17.4  50.6  0.9989  \n",
       "2    149.0         950.0        894.0   7.8  33.9  0.3594  \n",
       "3    173.0        1815.0       1582.0  26.4  41.9  1.4237  \n",
       "4     77.0        1363.0        632.0  37.4  14.7  0.9295  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['Unnamed: 0'], inplace=True) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "305a1d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NMHC(GT)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>NOx(GT)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>NO2(GT)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-200.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>898.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>933.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>1594.0</td>\n",
       "      <td>1098.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>51.7</td>\n",
       "      <td>0.9914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-200.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>1281.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>774.0</td>\n",
       "      <td>-200.0</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>1324.0</td>\n",
       "      <td>20.8</td>\n",
       "      <td>43.6</td>\n",
       "      <td>1.0614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-200.0</td>\n",
       "      <td>9.9</td>\n",
       "      <td>975.0</td>\n",
       "      <td>349.0</td>\n",
       "      <td>638.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>1243.0</td>\n",
       "      <td>1064.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>74.6</td>\n",
       "      <td>0.6826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-200.0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>749.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1690.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>31.7</td>\n",
       "      <td>21.5</td>\n",
       "      <td>0.9902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-200.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>647.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>962.0</td>\n",
       "      <td>828.0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>54.5</td>\n",
       "      <td>0.6022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NMHC(GT)  C6H6(GT)  PT08.S2(NMHC)  NOx(GT)  PT08.S3(NOx)  NO2(GT)  \\\n",
       "0    -200.0       8.0          898.0    122.0         933.0    105.0   \n",
       "1    -200.0      19.4         1281.0   -200.0         774.0   -200.0   \n",
       "2    -200.0       9.9          975.0    349.0         638.0    223.0   \n",
       "3    -200.0      12.7         1075.0    103.0         749.0     98.0   \n",
       "4    -200.0       2.9          647.0    131.0        1054.0     85.0   \n",
       "\n",
       "   PT08.S4(NO2)  PT08.S5(O3)     T    RH      AH  \n",
       "0        1594.0       1098.0  17.0  51.7  0.9914  \n",
       "1        1952.0       1324.0  20.8  43.6  1.0614  \n",
       "2        1243.0       1064.0   5.6  74.6  0.6826  \n",
       "3        1690.0       1022.0  31.7  21.5  0.9902  \n",
       "4         962.0        828.0   8.4  54.5  0.6022  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca6641cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6250, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "158d733b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6250 entries, 0 to 6249\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   PT08.S1(CO)    6173 non-null   float64\n",
      " 1   NMHC(GT)       6173 non-null   float64\n",
      " 2   C6H6(GT)       6173 non-null   float64\n",
      " 3   PT08.S2(NMHC)  6173 non-null   float64\n",
      " 4   NOx(GT)        6173 non-null   float64\n",
      " 5   PT08.S3(NOx)   6173 non-null   float64\n",
      " 6   NO2(GT)        6173 non-null   float64\n",
      " 7   PT08.S4(NO2)   6173 non-null   float64\n",
      " 8   PT08.S5(O3)    6173 non-null   float64\n",
      " 9   T              6173 non-null   float64\n",
      " 10  RH             6173 non-null   float64\n",
      " 11  AH             6173 non-null   float64\n",
      "dtypes: float64(12)\n",
      "memory usage: 586.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "646b39d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PT08.S1(CO)      77\n",
       "NMHC(GT)         77\n",
       "C6H6(GT)         77\n",
       "PT08.S2(NMHC)    77\n",
       "NOx(GT)          77\n",
       "PT08.S3(NOx)     77\n",
       "NO2(GT)          77\n",
       "PT08.S4(NO2)     77\n",
       "PT08.S5(O3)      77\n",
       "T                77\n",
       "RH               77\n",
       "AH               77\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b8a714d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df_test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b463a7dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PT08.S1(CO)', 'NMHC(GT)', 'C6H6(GT)', 'PT08.S2(NMHC)', 'NOx(GT)',\n",
       "       'PT08.S3(NOx)', 'NO2(GT)', 'PT08.S4(NO2)', 'PT08.S5(O3)', 'T', 'RH',\n",
       "       'AH'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42a6e6ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NMHC(GT)', 'C6H6(GT)', 'PT08.S2(NMHC)', 'NOx(GT)', 'PT08.S3(NOx)',\n",
       "       'NO2(GT)', 'PT08.S4(NO2)', 'PT08.S5(O3)', 'T', 'RH', 'AH'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c77113d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.count of       PT08.S1(CO)  NMHC(GT)  C6H6(GT)  PT08.S2(NMHC)  NOx(GT)  PT08.S3(NOx)  \\\n",
       "0           797.0    -200.0       2.1          593.0    146.0        1212.0   \n",
       "1          1282.0    -200.0      11.0         1013.0    354.0         545.0   \n",
       "2           891.0    -200.0       7.6          882.0    342.0         885.0   \n",
       "3          1285.0    -200.0      18.1         1243.0    481.0         599.0   \n",
       "4           892.0    -200.0       7.3          869.0     71.0         953.0   \n",
       "...           ...       ...       ...            ...      ...           ...   \n",
       "6244        918.0    -200.0       4.5          737.0    220.0        1007.0   \n",
       "6245        824.0    -200.0       2.2          602.0     54.0        1138.0   \n",
       "6246       1003.0    -200.0       3.7          694.0    156.0         876.0   \n",
       "6247        894.0    -200.0       4.0          709.0     46.0         997.0   \n",
       "6248       1213.0    -200.0      21.6         1341.0    210.0         683.0   \n",
       "\n",
       "      NO2(GT)  PT08.S4(NO2)  PT08.S5(O3)     T    RH      AH  \n",
       "0        72.0         984.0        494.0  10.8  49.7  0.6429  \n",
       "1       141.0        1384.0       1287.0  17.4  50.6  0.9989  \n",
       "2       149.0         950.0        894.0   7.8  33.9  0.3594  \n",
       "3       173.0        1815.0       1582.0  26.4  41.9  1.4237  \n",
       "4        77.0        1363.0        632.0  37.4  14.7  0.9295  \n",
       "...       ...           ...          ...   ...   ...     ...  \n",
       "6244    105.0        1030.0        703.0   9.6  53.9  0.6425  \n",
       "6245     44.0        1337.0        593.0  21.1  63.8  1.5817  \n",
       "6246    116.0         976.0        663.0   7.7  53.0  0.5572  \n",
       "6247     53.0        1432.0        853.0  24.0  37.8  1.1077  \n",
       "6248    143.0        2090.0       1601.0  28.8  30.2  1.1761  \n",
       "\n",
       "[6173 rows x 12 columns]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1009c0d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.count of       NMHC(GT)  C6H6(GT)  PT08.S2(NMHC)  NOx(GT)  PT08.S3(NOx)  NO2(GT)  \\\n",
       "0       -200.0       8.0          898.0    122.0         933.0    105.0   \n",
       "1       -200.0      19.4         1281.0   -200.0         774.0   -200.0   \n",
       "2       -200.0       9.9          975.0    349.0         638.0    223.0   \n",
       "3       -200.0      12.7         1075.0    103.0         749.0     98.0   \n",
       "4       -200.0       2.9          647.0    131.0        1054.0     85.0   \n",
       "...        ...       ...            ...      ...           ...      ...   \n",
       "3216    -200.0      12.5         1068.0    171.0         899.0    139.0   \n",
       "3217    -200.0       9.6          964.0   -200.0         953.0   -200.0   \n",
       "3218    -200.0       1.2          522.0     61.0        1242.0     55.0   \n",
       "3219    -200.0       8.7          927.0   -200.0         750.0   -200.0   \n",
       "3220    -200.0      10.7         1004.0     90.0         724.0    114.0   \n",
       "\n",
       "      PT08.S4(NO2)  PT08.S5(O3)     T    RH      AH  \n",
       "0           1594.0       1098.0  17.0  51.7  0.9914  \n",
       "1           1952.0       1324.0  20.8  43.6  1.0614  \n",
       "2           1243.0       1064.0   5.6  74.6  0.6826  \n",
       "3           1690.0       1022.0  31.7  21.5  0.9902  \n",
       "4            962.0        828.0   8.4  54.5  0.6022  \n",
       "...            ...          ...   ...   ...     ...  \n",
       "3216        1663.0       1374.0  23.8  28.2  0.8219  \n",
       "3217        1513.0        770.0  26.3  24.8  0.8393  \n",
       "3218        1070.0        471.0  10.8  78.7  1.0202  \n",
       "3219        1659.0        727.0  34.0  33.2  1.7395  \n",
       "3220        1704.0        899.0  31.8  34.5  1.5911  \n",
       "\n",
       "[3184 rows x 11 columns]>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0f7087",
   "metadata": {},
   "source": [
    "Extracting the Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6080b8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df[['NMHC(GT)', 'C6H6(GT)', 'PT08.S2(NMHC)', 'NOx(GT)',\n",
    "                  'PT08.S3(NOx)', 'NO2(GT)', 'PT08.S4(NO2)', 'PT08.S5(O3)',\n",
    "                  'T', 'RH', 'AH']]\n",
    "Y_train = df['PT08.S1(CO)']                  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0cd763",
   "metadata": {},
   "source": [
    "Normalizing the data from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2c010333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy is used for fast array operations and vectorization\n",
    "\n",
    "class StandardScalerFromScratch:\n",
    "    def __init__(self, epsilon=1e-8):\n",
    "        \"\"\"\n",
    "        Constructor for the StandardScalerFromScratch class.\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        epsilon : float\n",
    "            A small constant added to the denominator during scaling to prevent\n",
    "            division by zero (important when a feature has zero variance).\n",
    "            \n",
    "        Attributes initialized:\n",
    "        -----------------------\n",
    "        self.mean_ : stores feature-wise means (computed during fit).\n",
    "        self.std_  : stores feature-wise standard deviations (computed during fit).\n",
    "        \"\"\"\n",
    "        self.mean_ = None\n",
    "        self.std_ = None\n",
    "        self.epsilon = epsilon   # helps avoid numerical instability\n",
    "    \n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        Compute the mean and standard deviation for each feature (column).\n",
    "        These values will later be used to scale the data.\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Input training data of shape (n_samples, n_features).\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        self : object\n",
    "            Returns the scaler itself, enabling method chaining.\n",
    "        \"\"\"\n",
    "        # Convert to NumPy array (ensures consistency even if input is list/pandas DataFrame)\n",
    "        X = np.asarray(X, dtype=np.float64)\n",
    "        \n",
    "        # Error handling: input must be 2D (samples, features)\n",
    "        if X.ndim != 2:\n",
    "            raise ValueError(\"Input data must be 2D of shape (n_samples, n_features)\")\n",
    "        \n",
    "        # Store column-wise mean and std (population std with ddof=0)\n",
    "        self.mean_ = X.mean(axis=0)\n",
    "        self.std_ = X.std(axis=0, ddof=0)\n",
    "        \n",
    "        return self   # Returning self allows calls like scaler.fit(X).transform(X)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Scale the dataset using the mean and std computed in fit().\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Input data of shape (n_samples, n_features).\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        X_scaled : np.ndarray\n",
    "            Standardized data where each feature has mean≈0 and std≈1.\n",
    "        \"\"\"\n",
    "        # Check that fit() has been called before transform()\n",
    "        if self.mean_ is None or self.std_ is None:\n",
    "            raise ValueError(\"Scaler has not been fitted yet. Call `fit` first.\")\n",
    "        \n",
    "        # Convert to NumPy array\n",
    "        X = np.asarray(X, dtype=np.float64)\n",
    "        \n",
    "        # Error handling: dimensions must match fitted data\n",
    "        if X.shape[1] != self.mean_.shape[0]:\n",
    "            raise ValueError(\"Shape mismatch: input data must have the same number of features as training data\")\n",
    "        \n",
    "        # Apply scaling: (X - mean) / (std + epsilon)\n",
    "        return (X - self.mean_) / (self.std_ + self.epsilon)\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        \"\"\"\n",
    "        Convenience method: fits to data, then transforms it.\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Input data of shape (n_samples, n_features).\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        X_scaled : np.ndarray\n",
    "            Standardized version of input.\n",
    "        \"\"\"\n",
    "        return self.fit(X).transform(X)  # Method chaining\n",
    "    \n",
    "    def inverse_transform(self, X_scaled):\n",
    "        \"\"\"\n",
    "        Convert scaled data back to original representation.\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        X_scaled : np.ndarray\n",
    "            Standardized data of shape (n_samples, n_features).\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        X_original : np.ndarray\n",
    "            Data in the original scale (before normalization).\n",
    "        \"\"\"\n",
    "        if self.mean_ is None or self.std_ is None:\n",
    "            raise ValueError(\"Scaler has not been fitted yet. Call `fit` first.\")\n",
    "        \n",
    "        X_scaled = np.asarray(X_scaled, dtype=np.float64)\n",
    "        \n",
    "        # Inverse operation: X = X_scaled * std + mean\n",
    "        return X_scaled * (self.std_ + self.epsilon) + self.mean_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae61fdf7",
   "metadata": {},
   "source": [
    "🚦 Key Things to Remember (Interview POV)\n",
    "\n",
    "Why normalize?\n",
    "\n",
    "To ensure features are on a similar scale, especially for algorithms using gradient descent or distance-based methods (k-NN, SVM, k-Means).\n",
    "\n",
    "Prevents features with larger magnitudes from dominating updates.\n",
    "\n",
    "fit vs transform vs fit_transform\n",
    "\n",
    "fit() → calculates parameters (mean, std) from training data only.\n",
    "\n",
    "transform() → applies the scaling using those parameters.\n",
    "\n",
    "fit_transform() → shortcut = fit() + transform() on the same data.\n",
    "\n",
    "Rule: Always .fit() on train and .transform() both train & test with same params (avoid data leakage).\n",
    "\n",
    "Why epsilon?\n",
    "\n",
    "Prevents division by zero if a column has constant values (std = 0).\n",
    "\n",
    "OOP best practice:\n",
    "\n",
    "Attributes (mean_, std_) are saved inside the object, so you can call transform() multiple times consistently.\n",
    "\n",
    "Error handling ensures user doesn’t misuse the API.\n",
    "\n",
    "Complexity\n",
    "\n",
    "Fit: O(n·d)\n",
    "\n",
    "Transform: O(n·d)\n",
    "\n",
    "Memory: O(d) (stores mean & std only)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4868f21",
   "metadata": {},
   "source": [
    "❓ Interviewer Question Bank (Exhaustive)\n",
    "Conceptual\n",
    "\n",
    "Why do we normalize data before training ML models?\n",
    "\n",
    "Which models benefit the most from standardization? (hint: GD-based, distance-based).\n",
    "\n",
    "Difference between standardization and min-max scaling.\n",
    "\n",
    "Why should we only fit on training data and not test?\n",
    "\n",
    "What happens if a feature has zero variance?\n",
    "\n",
    "How does normalization affect gradient descent convergence?\n",
    "\n",
    "When might you not want to standardize? (e.g., tree-based models).\n",
    "\n",
    "Compare z-score normalization vs min-max scaling in terms of outlier sensitivity.\n",
    "\n",
    "Implementation-focused\n",
    "\n",
    "Explain what fit(), transform(), and fit_transform() do.\n",
    "\n",
    "Why do we add epsilon in the denominator?\n",
    "\n",
    "Show how you’d implement an inverse_transform().\n",
    "\n",
    "What errors could occur if you call transform() before fit()?\n",
    "\n",
    "How do you check for shape mismatches between train/test?\n",
    "\n",
    "Edge Cases\n",
    "\n",
    "What happens if your dataset has missing values (NaNs)?\n",
    "\n",
    "If all values in a column are identical, what does standardization yield?\n",
    "\n",
    "How do you handle categorical features during normalization?\n",
    "\n",
    "If you scale test data with its own mean and std, what’s the issue?\n",
    "\n",
    "Extensions\n",
    "\n",
    "Can you extend this to include partial_fit() for streaming data?\n",
    "\n",
    "How would you adapt this for sparse matrices?\n",
    "\n",
    "Can you make this class handle both float32 and float64 for efficiency?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7189b35",
   "metadata": {},
   "source": [
    "What is Data Leakage?\n",
    "\n",
    "Data leakage happens when information from outside the training dataset (e.g., from the validation or test set, or from the future) sneaks into the model during training.\n",
    "This causes your model to look artificially good during training/validation but fail badly on unseen real-world data.\n",
    "\n",
    "📌 Types of Data Leakage\n",
    "1. Preprocessing leakage\n",
    "\n",
    "Example: You scale your entire dataset (fit scaler on train+test combined) before splitting into train/test.\n",
    "\n",
    "The mean/std of test features “leaked” into training.\n",
    "\n",
    "Your model indirectly “saw” test data distribution.\n",
    "\n",
    "👉 Fix: Always fit preprocessing (e.g., normalization, imputation, encoding) only on training, then transform train/test with the same params.\n",
    "\n",
    "2. Feature leakage\n",
    "\n",
    "Example: A feature contains info that wouldn’t be available at prediction time.\n",
    "\n",
    "Predicting hospital readmission using “days until readmission” as a feature.\n",
    "\n",
    "Predicting churn using “account closure date” as a feature.\n",
    "\n",
    "Predicting loan default while including “loan repayment status” in input.\n",
    "\n",
    "👉 Fix: Only include features available before prediction time.\n",
    "\n",
    "3. Temporal leakage (time-series leakage)\n",
    "\n",
    "Example: Using future data to predict the past.\n",
    "\n",
    "Predicting stock price for Jan using features from Feb.\n",
    "\n",
    "Training with shuffled data in a time-series task.\n",
    "\n",
    "👉 Fix: Always split train/validation/test respecting time order.\n",
    "\n",
    "4. Target leakage\n",
    "\n",
    "Example: Features are too closely related to the target.\n",
    "\n",
    "Predicting “whether someone will default” using “credit score after default event.”\n",
    "\n",
    "Predicting “will a transaction be fraudulent?” using “is_fraud” column disguised.\n",
    "\n",
    "👉 Fix: Remove features that encode or strongly correlate with the label itself.\n",
    "\n",
    "🎯 Interview-Style Answer (30s version)\n",
    "\n",
    "“Data leakage occurs when information that shouldn’t be available at training time — such as test data statistics, future information, or target-related features — leaks into the training process. This makes the model perform unrealistically well in training but fail in production. Common examples are normalizing with test data, including post-outcome features, or using future values in time-series. The fix is to strictly separate train/test and only fit preprocessing steps on the training set.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e5495817",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScalerFromScratch()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(df_test) \n",
    "\n",
    "normalized_features_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3c0f91",
   "metadata": {},
   "source": [
    "***You need to explain the choice of the type of Feature scaling you did.***\n",
    "\n",
    "\n",
    "Why did you use Z-Score scaling? Were there outliers in the data? Which type of feature scaling is sensitive to outliers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bb3178",
   "metadata": {},
   "source": [
    "If after transformation, still there exists outliers or skewness, then consider performing log transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0a402046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMHC(GT)         7.481820e-18\n",
      "C6H6(GT)        -4.604197e-18\n",
      "PT08.S2(NMHC)   -1.234500e-16\n",
      "NOx(GT)         -4.604197e-18\n",
      "PT08.S3(NOx)    -6.100561e-17\n",
      "NO2(GT)         -5.064617e-17\n",
      "PT08.S4(NO2)    -1.945273e-16\n",
      "PT08.S5(O3)      9.208394e-17\n",
      "T                2.762518e-17\n",
      "RH              -3.683358e-17\n",
      "AH              -1.726574e-18\n",
      "dtype: float64\n",
      "NMHC(GT)         1.000081\n",
      "C6H6(GT)         1.000081\n",
      "PT08.S2(NMHC)    1.000081\n",
      "NOx(GT)          1.000081\n",
      "PT08.S3(NOx)     1.000081\n",
      "NO2(GT)          1.000081\n",
      "PT08.S4(NO2)     1.000081\n",
      "PT08.S5(O3)      1.000081\n",
      "T                1.000081\n",
      "RH               1.000081\n",
      "AH               1.000081\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "mean = normalized_features_df.mean()\n",
    "std = normalized_features_df.std()\n",
    "\n",
    "print(mean)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36287b7a",
   "metadata": {},
   "source": [
    "After transformation we can see that mean is very close to zero for all features , and the standard deviation is close to one for all features. So transformations can be considered successFul."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0264ad4f",
   "metadata": {},
   "source": [
    "Implementing the Linear Regression from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd721c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionGD:\n",
    "    # This is the Constructor - the purpose is to initialize the hyperparameters\n",
    "    def __init__(self, learning_rate=0.01, epochs=1000, tol=1e-8, verbose=False):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.tol = tol\n",
    "        self.verbose = verbose\n",
    "        self.weights = None\n",
    "        self.loss_history = []\n",
    "\n",
    "    def add_bias(self, X):\n",
    "        \"\"\"Add bias column (intercept term).\"\"\"\n",
    "        return np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "\n",
    "    def predict_raw(self, X):\n",
    "        \"\"\"Return raw predictions (X @ weights).\"\"\"\n",
    "        return X @ self.weights\n",
    "\n",
    "    def calculate_loss(self, X, Y):\n",
    "        \"\"\"Mean Squared Error (MSE).\"\"\"\n",
    "        m = len(Y)\n",
    "        residuals = self.predict_raw(X) - Y\n",
    "        return float((residuals.T @ residuals)/(2*m))\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        \"\"\"Train using Gradient Descent.\"\"\"\n",
    "        X = np.asarray(X, dtype=np.float64)\n",
    "        Y = np.asarray(Y, dtype=np.float64).reshape(-1, 1)\n",
    "\n",
    "        X = self.add_bias(X)\n",
    "        m, n = X.shape\n",
    "\n",
    "        # Initialize weights\n",
    "        self.weights = np.zeros((n, 1))\n",
    "\n",
    "        prev_loss = float(\"inf\")\n",
    "        for epoch in range(self.epochs):\n",
    "            # Forward Pass\n",
    "            preds = self.predict_raw(X)\n",
    "\n",
    "            # Backward pass\n",
    "            # Gradient of MSE\n",
    "            gradients = (X.T @ (preds - Y)) / m    # Formula is actually (-1/m) X.T @ (Y - preds)\n",
    "\n",
    "            # Weight update\n",
    "            self.weights -= self.learning_rate * gradients\n",
    "\n",
    "            # Compute and store loss\n",
    "            loss = self.calculate_loss(X, Y)\n",
    "            self.loss_history.append(loss)\n",
    "\n",
    "            # Early stopping\n",
    "            if abs(prev_loss - loss) < self.tol:\n",
    "                if self.verbose:\n",
    "                    print(f\"Early stopping at epoch {epoch}, Loss = {loss:.6f}\")\n",
    "                break\n",
    "            prev_loss = loss\n",
    "\n",
    "            if self.verbose and epoch % 100 == 0:\n",
    "                print(f\"Epoch {epoch}, Loss = {loss:.6f}\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions on new data.\"\"\"\n",
    "        X = np.asarray(X, dtype=np.float64)\n",
    "        X = self.add_bias(X)\n",
    "        return self.predict_raw(X)\n",
    "\n",
    "    def score(self, X, Y):\n",
    "        \"\"\"Compute R² score.\"\"\"\n",
    "        Y = np.asarray(Y, dtype=np.float64).reshape(-1, 1)\n",
    "        preds = self.predict(X)\n",
    "        ss_res = np.sum((Y - preds) ** 2)\n",
    "        ss_tot = np.sum((Y - np.mean(Y)) ** 2)\n",
    "        return 1 - ss_res / ss_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0e39a5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss = 1185686.634669\n",
      "Epoch 100, Loss = 151807.749989\n",
      "Epoch 200, Loss = 25114.229218\n",
      "Epoch 300, Loss = 8037.675146\n",
      "Epoch 400, Loss = 5681.014327\n",
      "Epoch 500, Loss = 5322.204312\n",
      "Epoch 600, Loss = 5246.671220\n",
      "Epoch 700, Loss = 5218.563286\n",
      "Epoch 800, Loss = 5202.607675\n",
      "Epoch 900, Loss = 5191.876222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kn/v162b6m93yj8cdzbl4by_12r0000gp/T/ipykernel_17216/1934135126.py:25: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  return float((residuals.T @ residuals) / m)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.LinearRegressionGD at 0x123b43230>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegressionGD(learning_rate=0.01, epochs=1000, verbose=True)\n",
    "model.fit(X_train_scaled,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4d1d37dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Cost: 5184.180865057258\n"
     ]
    }
   ],
   "source": [
    "print(\"Final Cost:\", model.loss_history[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0686b494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final parameters: [[1053.09206916]\n",
      " [  33.21747102]\n",
      " [  51.6147512 ]\n",
      " [  75.1864726 ]\n",
      " [  23.21228718]\n",
      " [ -33.55860488]\n",
      " [  -8.05796003]\n",
      " [  28.42022405]\n",
      " [  97.32111494]\n",
      " [  16.12220203]\n",
      " [  54.30949035]\n",
      " [  37.48752197]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Final parameters:\", model.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6f067ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1086.94279247]\n",
      " [1254.9880515 ]\n",
      " [1141.17789745]\n",
      " ...\n",
      " [ 822.92137051]\n",
      " [1016.61612681]\n",
      " [1084.35051704]]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test_scaled)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "911c59ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.8519709992865122\n",
      "Updated weights:\n",
      " [[-0.00431997]\n",
      " [ 0.00735799]\n",
      " [ 0.00516885]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kn/v162b6m93yj8cdzbl4by_12r0000gp/T/ipykernel_14813/2274772375.py:21: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  print(\"Loss:\", float(loss))\n"
     ]
    }
   ],
   "source": [
    "# Single Forward and Backward Pass\n",
    "import numpy as np\n",
    "\n",
    "# Example data\n",
    "np.random.seed(42)\n",
    "X = np.random.randn(5, 3)          # 5 samples, 3 features\n",
    "y = np.random.randn(5, 1)          # targets\n",
    "w = np.zeros((X.shape[1], 1))      # initialize weights (3x1)\n",
    "alpha = 0.01                       # learning rate\n",
    "m = X.shape[0]                     # number of samples\n",
    "\n",
    "# ---------- Forward Pass ----------\n",
    "preds = X @ w                      # predictions (5x1)\n",
    "residuals = preds - y              # error (5x1)\n",
    "loss = (residuals.T @ residuals) / m   # Mean Squared Error (scalar)\n",
    "\n",
    "# ---------- Backward Pass ----------\n",
    "gradients = (X.T @ residuals) / m  # gradient wrt weights (3x1)\n",
    "w = w - alpha * gradients          # weight update\n",
    "\n",
    "print(\"Loss:\", float(loss))\n",
    "print(\"Updated weights:\\n\", w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0d1deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a better code from scratch.\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class LinearRegression:\n",
    "    def __init__(self, lr: int = 0.01, n_iters: int = 1000) -> None:\n",
    "        self.lr = lr\n",
    "        self.n_iters = n_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        num_samples, num_features = X.shape     # X shape [N, f]\n",
    "        self.weights = np.random.rand(num_features)  # W shape [f, 1]\n",
    "        self.bias = 0\n",
    "\n",
    "        for i in range(self.n_iters):\n",
    "\n",
    "            # y_pred shape should be N, 1\n",
    "            y_pred = np.dot(X, self.weights) + self.bias\n",
    "\n",
    "            # X -> [N,f]\n",
    "            # y_pred -> [N]\n",
    "            # dw -> [f]\n",
    "            dw = (1 / num_samples) * np.dot(X.T, y_pred - y)\n",
    "            db = (1 / num_samples) * np.sum(y_pred - y)\n",
    "\n",
    "            self.weights = self.weights - self.lr * dw\n",
    "            self.bias = self.bias - self.lr * db\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.dot(X, self.weights) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a696f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Linear_Regression:\n",
    "    def __init__(self,learning_rate=0.01,epochs=100):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self,X,Y):\n",
    "        X = np.asarray(X,dtype=np.float64) \n",
    "        Y = np.asarray(Y,dtype=np.float64)\n",
    "\n",
    "        m,n = X.shape\n",
    "        self.weights = np.zeros((n,1))\n",
    "        self.bias = 0\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            y_pred = X @ self.weights + self.bias     #(m,1)\n",
    "\n",
    "            dw = (1/m)*(X.T @ (y_pred - Y))\n",
    "            db = (1/m)*np.sum(y_pred - Y)\n",
    "\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "\n",
    "            self.calculate_loss(Y,y_pred)\n",
    "\n",
    "        return self    \n",
    "\n",
    "    def calculate_loss(self,Y,y_pred):\n",
    "        return np.mean((Y - y_pred)**2)\n",
    "\n",
    "    def predict(self,X):\n",
    "        X = np.asarray(X,dtype=np.float64)\n",
    "        y_pred = X @ self.weights + self.bias\n",
    "        return y_pred\n",
    "    \n",
    "np.random.seed(42)\n",
    "X = np.random.randn(200,4)\n",
    "Y = np.random.randn(200,1)\n",
    "\n",
    "model = Linear_Regression()\n",
    "model.fit(X,Y)\n",
    "\n",
    "print(model.predict(X[:10]))\n",
    "print(\"-------\")\n",
    "print(Y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01642b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0996359 ]\n",
      " [0.07937433]\n",
      " [0.04265128]\n",
      " [0.18518063]\n",
      " [0.03827195]\n",
      " [0.14940005]\n",
      " [0.05840756]\n",
      " [0.0690662 ]\n",
      " [0.13405166]\n",
      " [0.182802  ]]\n",
      "-------\n",
      "[[ 0.93828381]\n",
      " [-0.51604473]\n",
      " [ 0.09612078]\n",
      " [-0.46227529]\n",
      " [-0.43449623]\n",
      " [-0.30917212]\n",
      " [ 0.22213377]\n",
      " [-0.47874862]\n",
      " [ 1.25575613]\n",
      " [-0.8946073 ]]\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
