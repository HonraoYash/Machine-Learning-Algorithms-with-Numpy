{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1b595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter # Dont forget to import this dependency\n",
    "\n",
    "class KNearestNeighbors:\n",
    "    \"\"\"\n",
    "    K-Nearest Neighbors (KNN) from scratch.\n",
    "    Supports classification and regression.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k=3, mode=\"classification\", distance=\"euclidean\"):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        k : int\n",
    "            Number of neighbors to consider.\n",
    "        mode : str, \"classification\" or \"regression\"\n",
    "            Determines prediction type.\n",
    "        distance : str, \"euclidean\" or \"manhattan\"\n",
    "            Distance metric.\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.mode = mode\n",
    "        self.distance = distance\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def _compute_distances(self, X):\n",
    "        \"\"\"Compute pairwise distances between X and stored training data.\"\"\"\n",
    "        if self.distance == \"euclidean\":\n",
    "            # Efficient vectorized Euclidean distance\n",
    "            # (a-b)^2 = a^2 + b^2 - 2ab\n",
    "            X2 = np.sum(X**2, axis=1, keepdims=True)\n",
    "            X_train2 = np.sum(self.X_train**2, axis=1)\n",
    "            cross = X @ self.X_train.T\n",
    "            dists = np.sqrt(X2 + X_train2 - 2 * cross)\n",
    "        elif self.distance == \"manhattan\":\n",
    "            # Broadcasting trick for L1 distance\n",
    "            dists = np.sum(np.abs(X[:, np.newaxis] - self.X_train), axis=2)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported distance metric\")\n",
    "        return dists\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Store training data.\"\"\"\n",
    "        self.X_train = np.asarray(X, dtype=np.float64)\n",
    "        self.y_train = np.asarray(y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict labels for given data.\"\"\"\n",
    "        X = np.asarray(X, dtype=np.float64)\n",
    "        dists = self._compute_distances(X)\n",
    "\n",
    "        # Find k nearest indices\n",
    "        neighbors_idx = np.argsort(dists, axis=1)[:, :self.k]\n",
    "        neighbors_labels = self.y_train[neighbors_idx]\n",
    "\n",
    "        if self.mode == \"classification\":\n",
    "            # Majority vote\n",
    "            preds = []\n",
    "            for row in neighbors_labels:\n",
    "                most_common = Counter(row).most_common(1)[0][0] # Each row is a list/array of labels of the KNN, Counter function creates a dictionary\n",
    "                # of the labels:count , and most_common returns a tuple of (label,count), since it's (1)-> it returns a single tuple and first [0]\n",
    "                # extracts that tuple and second [0] extracts the first value from that tuple which is the label. \n",
    "                preds.append(most_common)\n",
    "            return np.array(preds)\n",
    "        elif self.mode == \"regression\":\n",
    "            # Mean of neighbors\n",
    "            return np.mean(neighbors_labels, axis=1)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported mode\")\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\"Evaluate model performance.\"\"\"\n",
    "        preds = self.predict(X)\n",
    "        if self.mode == \"classification\":\n",
    "            return np.mean(preds == y)\n",
    "        elif self.mode == \"regression\":\n",
    "            return np.mean((preds - y) ** 2)  # MSE\n",
    "        \n",
    "np.random.seed(42)\n",
    "X_train = np.random.rand(10, 2)\n",
    "y_train = np.random.choice([0, 1], size=10)\n",
    "\n",
    "knn = KNearestNeighbors(k=3, mode=\"classification\")\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "X_test = np.random.rand(5, 2)\n",
    "print(\"Predictions:\", knn.predict(X_test))\n",
    "\n",
    "y_train_reg = np.random.rand(10)\n",
    "knn = KNearestNeighbors(k=3,mode=\"regression\")\n",
    "knn.fit(X_train,y_train_reg)\n",
    "print(\"Predictions (regression):\", knn.predict(X_test))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "477cdddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1553be41",
   "metadata": {},
   "source": [
    "🔹 What X2 = np.sum(X**2, axis=1, keepdims=True) really means\n",
    "\n",
    "X: shape (m_test, d) → m_test points, d features each.\n",
    "\n",
    "X**2: square each element → shape (m_test, d).\n",
    "\n",
    "np.sum(..., axis=1, keepdims=True) → sum across features → shape (m_test, 1).\n",
    "\n",
    "So for each test sample, you’re computing:\n",
    "\n",
    "𝑋\n",
    "2\n",
    "[\n",
    "𝑖\n",
    "]\n",
    "=\n",
    "∑\n",
    "𝑘\n",
    "=\n",
    "1\n",
    "𝑑\n",
    "(\n",
    "𝑥\n",
    "𝑖\n",
    ",\n",
    "𝑘\n",
    ")\n",
    "2\n",
    "X2[i]=\n",
    "k=1\n",
    "∑\n",
    "d\n",
    "\t​\n",
    "\n",
    "(x\n",
    "i,k\n",
    "\t​\n",
    "\n",
    ")\n",
    "2\n",
    "\n",
    "👉 This is the squared norm (‖x‖²) of each row vector, not just squaring elements individually.\n",
    "\n",
    "🔹 Why do we need the sum?\n",
    "\n",
    "Because of the Euclidean distance formula:\n",
    "\n",
    "∥\n",
    "𝑥\n",
    "−\n",
    "𝑦\n",
    "∥\n",
    "2\n",
    "=\n",
    "∥\n",
    "𝑥\n",
    "∥\n",
    "2\n",
    "+\n",
    "∥\n",
    "𝑦\n",
    "∥\n",
    "2\n",
    "−\n",
    "2\n",
    "(\n",
    "𝑥\n",
    "⋅\n",
    "𝑦\n",
    ")\n",
    "∥x−y∥\n",
    "2\n",
    "=∥x∥\n",
    "2\n",
    "+∥y∥\n",
    "2\n",
    "−2(x⋅y)\n",
    "\n",
    "∥\n",
    "𝑥\n",
    "∥\n",
    "2\n",
    "=\n",
    "∑\n",
    "𝑘\n",
    "𝑥\n",
    "𝑘\n",
    "2\n",
    "∥x∥\n",
    "2\n",
    "=∑\n",
    "k\n",
    "\t​\n",
    "\n",
    "x\n",
    "k\n",
    "2\n",
    "\t​\n",
    "\n",
    " → that’s why we take the sum.\n",
    "\n",
    "If we only did X**2, we’d have each squared coordinate, not the total squared length.\n",
    "\n",
    "🔹 Shape intuition\n",
    "\n",
    "Say X = [[1,2], [3,4]] → shape (2,2)\n",
    "\n",
    "X**2 = [[1,4], [9,16]]\n",
    "\n",
    "np.sum(..., axis=1, keepdims=True) =\n",
    "[[1+4], [9+16]] = [[5], [25]] → squared norms.\n",
    "\n",
    "That way:\n",
    "\n",
    "X2: shape (m_test,1)\n",
    "\n",
    "X_train2: shape (m_train,)\n",
    "\n",
    "Combine them with broadcasting in the formula.\n",
    "\n",
    "🎯 Intuition\n",
    "\n",
    "We don’t just want to square elements; we want the sum of squares per vector (per row) because that’s exactly the squared length used in the Euclidean distance trick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf52d707",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter # Dont forget to import this dependency\n",
    "\n",
    "class KNearestNeighbors:\n",
    "    \"\"\"\n",
    "    K-Nearest Neighbors (KNN) from scratch.\n",
    "    Supports classification and regression.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, k=3, mode=\"classification\", distance=\"euclidean\"):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        k : int\n",
    "            Number of neighbors to consider.\n",
    "        mode : str, \"classification\" or \"regression\"\n",
    "            Determines prediction type.\n",
    "        distance : str, \"euclidean\" or \"manhattan\"\n",
    "            Distance metric.\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.mode = mode\n",
    "        self.distance = distance\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def _compute_distances(self, X):\n",
    "        \"\"\"Compute pairwise distances between X and stored training data.\"\"\"\n",
    "        if self.distance == \"euclidean\":\n",
    "            # Efficient vectorized Euclidean distance\n",
    "            # (a-b)^2 = a^2 + b^2 - 2ab\n",
    "            X2 = np.sum(X**2, axis=1, keepdims=True)\n",
    "            X_train2 = np.sum(self.X_train**2, axis=1)\n",
    "            cross = X @ self.X_train.T\n",
    "            dists = np.sqrt(X2 + X_train2 - 2 * cross)\n",
    "        elif self.distance == \"manhattan\":\n",
    "            # Broadcasting trick for L1 distance\n",
    "            dists = np.sum(np.abs(X[:, np.newaxis] - self.X_train), axis=2)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported distance metric\")\n",
    "        return dists\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Store training data.\"\"\"\n",
    "        self.X_train = np.asarray(X, dtype=np.float64)\n",
    "        self.y_train = np.asarray(y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict labels for given data.\"\"\"\n",
    "        X = np.asarray(X, dtype=np.float64)\n",
    "        dists = self._compute_distances(X)\n",
    "\n",
    "        # Find k nearest indices\n",
    "        neighbors_idx = np.argsort(dists, axis=1)[:, :self.k]\n",
    "        neighbors_labels = self.y_train[neighbors_idx]\n",
    "\n",
    "        if self.mode == \"classification\":\n",
    "            # Majority vote\n",
    "            preds = []\n",
    "            for row in neighbors_labels:\n",
    "                most_common = Counter(row).most_common(1)[0][0] # Each row is a list/array of labels of the KNN, Counter function creates a dictionary\n",
    "                # of the labels:count , and most_common returns a tuple of (label,count), since it's (1)-> it returns a single tuple and first [0]\n",
    "                # extracts that tuple and second [0] extracts the first value from that tuple which is the label. \n",
    "                preds.append(most_common)\n",
    "            return np.array(preds)\n",
    "        elif self.mode == \"regression\":\n",
    "            # Mean of neighbors\n",
    "            return np.mean(neighbors_labels, axis=1)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported mode\")\n",
    "\n",
    "    def score(self, X, y):\n",
    "        \"\"\"Evaluate model performance.\"\"\"\n",
    "        preds = self.predict(X)\n",
    "        if self.mode == \"classification\":\n",
    "            return np.mean(preds == y)\n",
    "        elif self.mode == \"regression\":\n",
    "            return np.mean((preds - y) ** 2)  # MSE\n",
    "        \n",
    "np.random.seed(42)\n",
    "X_train = np.random.rand(10, 2)\n",
    "y_train = np.random.choice([0, 1], size=10)\n",
    "\n",
    "knn = KNearestNeighbors(k=3, mode=\"classification\")\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "X_test = np.random.rand(5, 2)\n",
    "print(\"Predictions:\", knn.predict(X_test))\n",
    "\n",
    "y_train_reg = np.random.rand(10)\n",
    "knn = KNearestNeighbors(k=3,mode=\"regression\")\n",
    "knn.fit(X_train,y_train_reg)\n",
    "print(\"Predictions (regression):\", knn.predict(X_test))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b8c2116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [1 1 1 1 0]\n",
      "Predictions (regression): [0.35285689 0.55136222 0.57186389 0.13028021 0.5177212 ]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "X_train = np.random.rand(10, 2)\n",
    "y_train = np.random.choice([0, 1], size=10)\n",
    "\n",
    "knn = KNearestNeighbors(k=3, mode=\"classification\")\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "X_test = np.random.rand(5, 2)\n",
    "print(\"Predictions:\", knn.predict(X_test))\n",
    "\n",
    "y_train_reg = np.random.rand(10)\n",
    "knn = KNearestNeighbors(k=3,mode=\"regression\")\n",
    "knn.fit(X_train,y_train_reg)\n",
    "print(\"Predictions (regression):\", knn.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e299114d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "class KNearest_Neighbors:\n",
    "    def __init__(self, k=1, mode=\"classification\", distance=\"euclidean\"):\n",
    "        self.k = k\n",
    "        self.mode = mode\n",
    "        self.distance = distance\n",
    "\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        X = np.asarray(X,dtype=np.float64)\n",
    "        Y = np.asarray(y)\n",
    "        self.X_train = X\n",
    "        self.y_train = Y\n",
    "\n",
    "    def compute_distances(self,X):    \n",
    "        if self.distance == \"euclidean\":\n",
    "            X2 = np.sum(X ** 2, axis=1, keepdims=True)\n",
    "            X_train2 = np.sum(self.X_train ** 2, axis=1)\n",
    "            cross = X @ self.X_train.T\n",
    "            distance = np.sqrt(X2 + X_train2 - 2 * cross)\n",
    "            return distance\n",
    "        elif self.distance == \"manhattan\":\n",
    "            return np.sum(np.abs(X[:,np.newaxis] - self.X_train), axis=2)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported distance metric\")    \n",
    "        \n",
    "\n",
    "    def predict(self,X):\n",
    "        X = np.asarray(X,np.float64)\n",
    "        distances = self.compute_distances(X) \n",
    "\n",
    "        neighbor_idx = np.argsort(distances, axis=1)[:,:self.k]   \n",
    "        labels = self.y_train[neighbor_idx]\n",
    "\n",
    "        if self.mode == \"classification\":\n",
    "            preds = []\n",
    "            for row in labels:\n",
    "                most_common = Counter(row).most_common(1)[0][0]\n",
    "                preds.append(most_common)\n",
    "            return preds\n",
    "        elif self.mode == \"regression\":\n",
    "            return np.mean(labels,axis=1)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported mode\")   \n",
    "\n",
    "    def score(self,X,y):\n",
    "        y_preds = self.predict(X)\n",
    "        if self.mode == \"classification\":\n",
    "            return np.mean(y_preds == y)\n",
    "        else:\n",
    "            return np.mean((y_preds - y) ** 2)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d26165b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 1]\n",
      "[np.int64(1), np.int64(0), np.int64(1), np.int64(1), np.int64(0)]\n",
      "[0.32654077 0.57044397 0.52083426 0.96117202 0.84453385]\n",
      "[np.float64(0.20794166286818883), np.float64(0.03131329245555858), np.float64(0.7553614103176525), np.float64(0.9266588657937942), np.float64(0.20794166286818883)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(0.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "X = np.random.randn(10,2)\n",
    "Y = np.random.choice(2,10)\n",
    "\n",
    "model = KNearest_Neighbors(k=3,distance=\"euclidean\")\n",
    "model.fit(X,Y)\n",
    "\n",
    "X_test = np.random.randn(5,2)\n",
    "Y_test = np.random.choice(2,5)\n",
    "print(Y_test)\n",
    "print(model.predict(X_test))\n",
    "\n",
    "y_train_reg = np.random.rand(10)\n",
    "y_test_reg = np.random.rand(5)\n",
    "print(y_test_reg)\n",
    "model.fit(X,y_train_reg)\n",
    "print(model.predict(X_test))\n",
    "model.score(X_test,y_test_reg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
